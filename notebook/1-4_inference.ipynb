{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7733cf0",
   "metadata": {},
   "source": [
    "# 概要\n",
    "\n",
    "本ファイルは、学習済みモデルを使用して、3D物体検出モデルの推論・評価を実行します。 \n",
    "\n",
    "> 本ファイルで実行するスクリプトはsecond.pytorchをベースとしています。\n",
    "\n",
    "## Output\n",
    "本ファイルを実行することで、`results`ディレクトリに、推論結果(result.pkl)を出力します。\n",
    "\n",
    "```\n",
    "└ second.pytorc\n",
    "     └ checkpoints\n",
    "          └ {model_dir}\n",
    "                ├ results    <- 本ファイルにて生成されます\n",
    "                   └ step_xxxx    \n",
    "                       └─ result.pkl\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9098831",
   "metadata": {},
   "source": [
    "# 準備\n",
    "\n",
    "あらかじめ、 `data`ディレクトリに、`3d_labels_painted`ディレクトリと、`second.pytorch/checkpoints/{model_dir}` ディレクトリに学習済みモデルがあることを確認してください。\n",
    "\n",
    "> 本ファイルのデフォルトでは、公開の学習済みモデル`second.pytorch/checkpoints/pointpainting`を設定しています。\n",
    "\n",
    "\n",
    "```\n",
    "└ data\n",
    "    ├ 3d_labels\n",
    "    └ 3d_labels_painted\n",
    "        ├ maps\n",
    "        ├ samples\n",
    "            ├ CAM_FRONT\n",
    "            └ LIDAR_TOP\n",
    "        ├ v1.0-trainval\n",
    "        ├ gt_database        <- 1-2_create_dataset_metadata.ipynb にて生成\n",
    "        ├ infos_train.pkl    <- 1-2_create_dataset_metadata.ipynb にて生成\n",
    "        ├ infos_val.pkl      <- 1-2_create_dataset_metadata.ipynb にて生成\n",
    "        └ kitti_dbinfos_train.pkl  <- 1-2_create_dataset_metadata.ipynb にて生成\n",
    " \n",
    "├second.pytorch\n",
    "     └─ checkpoints\n",
    "          └ {model_dir}\n",
    "                ├── checkpoints.json\n",
    "                ├── {model-step}.tckpt <- 学習済みモデル\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e57c64",
   "metadata": {},
   "source": [
    "# 推論・評価\n",
    "\n",
    "検証データ(val)に対して推論と評価を実施します。  \n",
    "\n",
    "> 学習データと検証データはnuScenesデータセットで定義されています。  \n",
    "> 検証データはscene-0094とscene-0109 の2シーンで、\n",
    "> 学習データはそれ以外の35シーンです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0979d17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# パスの設定\n",
    "\n",
    "config_path = \"../second.pytorch/second/configs/nuscenes/pointpainting.config\"\n",
    "\n",
    "model_dir = \"../second.pytorch/checkpoints/pointpainting\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bc5c9ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  41 1984  992]\n",
      "Restoring parameters from /work/second.pytorch/checkpoints/pointpainting/voxelnet-24000.tckpt\n",
      "feature_map_size [1, 248, 124]\n",
      "Generate output labels...\n",
      "[100.0%][===================>][2.97it/s][00:15>00:00]   \n",
      "generate label finished(11.78/s). start eval:\n",
      "avg example to torch time: 4.511 ms\n",
      "avg prep time: 41.424 ms\n",
      "avg voxel_feature_extractor time = 0.699 ms\n",
      "avg middle forward time = 147.006 ms\n",
      "avg rpn forward time = 112.753 ms\n",
      "avg predict time = 29.899 ms\n",
      "Evaluation nusc                                                                 \n",
      "Nusc v1.0-trainval Evaluation\n",
      "car Nusc dist AP@0.5, 1.0, 2.0, 4.0 and TP errors\n",
      "4.76, 6.25, 7.26, 7.32\n",
      "trans_err, scale_err, orient_err, vel_err, attr_err: 0.2851, 0.2349, 2.4506, 1.0000, 0.9787\n",
      "pedestrian Nusc dist AP@0.5, 1.0, 2.0, 4.0 and TP errors\n",
      "0.00, 0.00, 0.00, 0.00\n",
      "trans_err, scale_err, orient_err, vel_err, attr_err: 1.0000, 1.0000, 1.0000, 1.0000, 1.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python ../second.pytorch/second/pytorch/train.py evaluate \\\n",
    "        --config_path=$config_path \\\n",
    "        --model_dir=$model_dir --measure_time=True --batch_size=4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2ca0c5",
   "metadata": {},
   "source": [
    "## （オプション）推論結果の確認\n",
    "\n",
    "推論データは pklファイルに保存されています。pklファイルを読み込みことで推論データを確認することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f570f9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result size:  187\n",
      "tensor([[ 13.5261,  -3.0028,  -0.9795,   1.8182,   4.2835,   1.7755,   1.5868],\n",
      "        [ 20.1477,   0.6293,  -1.1003,   1.8186,   4.2175,   1.7506,   1.5451],\n",
      "        [ 11.2831,  -6.6473,  -1.3337,   1.6925,   3.8947,   1.6504,  -1.4244],\n",
      "        [ 29.8661, -15.1257,  -1.7500,   1.6665,   3.7216,   1.6057,  -1.3606],\n",
      "        [ 41.2427,   8.1982,  -0.7761,   0.5630,   0.6865,   1.6484,   1.6287],\n",
      "        [ 20.5918,   8.8067,  -0.5628,   0.5593,   0.6855,   1.6449,  -1.9883]],\n",
      "       device='cuda:0')\n",
      "tensor([0.7926, 0.6244, 0.5773, 0.3626, 0.3595, 0.3067], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 1, 1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "result_pkl = \"../second.pytorch/checkpoints/pointpainting/eval_results/step_24000/result.pkl\"\n",
    "\n",
    "with open(result_pkl, 'rb') as f:\n",
    "    result = pickle.load(f)\n",
    "\n",
    "print(\"result size: \", len(result))\n",
    "print(result[0][\"box3d_lidar\"])  # (n, 7)  [x, y, z, l, h, w, rz]\n",
    "print(result[0][\"scores\"])  # (n)\n",
    "print(result[0][\"label_preds\"])  # (n)  0: car, 1:pedestrian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fe1e2a",
   "metadata": {},
   "source": [
    "以上"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
